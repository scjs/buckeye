{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository has Python classes for iterating through the annotations\n",
    "in the [Buckeye Corpus](http://buckeyecorpus.osu.edu/). They include \n",
    "cross-references between the .words, .phones, and .log files, and\n",
    "can be used to extract sound clips from the .wav files. The docstrings in\n",
    "`buckeye.py` and `containers.py` describe how to use the classes in more\n",
    "detail.\n",
    "\n",
    "The scripts can be installed directly from GitHub with pip using this command:\n",
    "\n",
    "    pip install git+http://github.com/scjs/buckeye.git\n",
    "\n",
    "You can also copy the `buckeye/` subdirectory into your working directory, or\n",
    "put it in your Python path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker\n",
    "\n",
    "A `Speaker` instance is created by pointing to one of the zipped speaker\n",
    "archives that can be downloaded from the corpus website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import buckeye\n",
    "\n",
    "speaker = buckeye.Speaker('./speakers/s01.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will open and process the annotations in each of the sub-archives inside\n",
    "the speaker archive (the tracks, such as `s0101a` and `s0101b`). If an optional\n",
    "`load_wavs` argument is set to `True` when creating a `Speaker` instance, the\n",
    "wav files associated with each track will also be loaded into memory. Otherwise,\n",
    "only the annotations are loaded.\n",
    "\n",
    "Each `Speaker` instance has the speaker's code-name, sex, age, and interviewer\n",
    "sex available as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s01 f y f\n"
     ]
    }
   ],
   "source": [
    "print speaker.name, speaker.sex, speaker.age, speaker.interviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracks can be accessed by iterating through the `Speaker` instance.\n",
    "There is more detail about accessing the annotations below under the heading\n",
    "**Tracks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0101a\n",
      "s0101b\n",
      "s0102a\n",
      "s0102b\n",
      "s0103a\n"
     ]
    }
   ],
   "source": [
    "for track in speaker:\n",
    "    print track.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracks can also be accessed through the `tracks` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Track(\"s01/s0101a.zip\"), Track(\"s01/s0101b.zip\"), Track(\"s01/s0102a.zip\"), Track(\"s01/s0102b.zip\"), Track(\"s01/s0103a.zip\")]\n"
     ]
    }
   ],
   "source": [
    "print speaker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track\n",
    "\n",
    "Each `Track` instance has `words`, `phones`, `log`, `txt`, and `wav` attributes that contain the corpus data from one track for one speaker. Each speaker has 6 or so tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speaker(\"./speakers/s01.zip\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track(\"s01/s0101a.zip\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track = speaker[0]\n",
    "track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words\n",
    "\n",
    "The `words` attribute stores a list of Word and Pause instances, created from the `.words` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pause('{B_TRANS}', 0.0, 0.102385),\n",
       " Pause('<SIL>', 0.102385, 4.275744),\n",
       " Pause('<NOISE>', 4.275744, 8.513518),\n",
       " Pause('<IVER>', 8.513518, 32.216575),\n",
       " Word('okay', 32.216575, 32.622045, ['ow', 'k', 'ey'], ['k', 'ay'], 'NN'),\n",
       " Pause('<IVER>', 32.622045, 37.129002),\n",
       " Pause('<VOCNOISE>', 37.129002, 38.123014),\n",
       " Pause('<IVER>', 38.123014, 44.617996),\n",
       " Word('um', 44.617996, 44.946848, ['ah', 'm'], ['ah', 'm'], 'UH'),\n",
       " Pause('<SIL>', 44.946848, 45.355708)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track.words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word instances have these nine attributes:\n",
    "\n",
    "* `orthography` (the word's spelling)\n",
    "* `beg` (word onset time, in seconds)\n",
    "* `end` (word offset time)\n",
    "* `dur` (duration)\n",
    "* `phonemic` (the canonical transcription)\n",
    "* `phonetic` (the close transcription)\n",
    "* `pos` (the word's part of speech)\n",
    "* `misaligned` (marked as True if the word has a negative duration, or if the phonetic transcription doesn't match what's in the `.phones` file)\n",
    "* `phones` (a list of references to Phone instances that have the labels and timing information for the phonetic transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay 32.216575 32.622045 0.40547 ['ow', 'k', 'ey'] ['k', 'ay'] NN False\n"
     ]
    }
   ],
   "source": [
    "word = track.words[4]\n",
    "\n",
    "print word.orthography, word.beg, word.end, word.dur, word.phonemic, word.phonetic, word.pos, word.misaligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phones are retrieved based on the timestamps for the word and for the entries in the `.phones` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Phone('k', 32.216575, 32.376593), Phone('ay', 32.376593, 32.622045)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phones have four attributes:\n",
    "\n",
    "* `seg` (the pseudo-ARPABET transcription of the phone)\n",
    "* `beg` (onset time)\n",
    "* `end` (offset time)\n",
    "* `dur` (duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 32.216575 32.376593 0.160018\n",
      "ay 32.376593 32.622045 0.245452\n"
     ]
    }
   ],
   "source": [
    "for phone in word.phones:\n",
    "    print phone.seg, phone.beg, phone.end, phone.dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the annotations are things like `<SIL>` (silence) or `<IVER>` (the interviewer's turn). These are yielded as Pause instances, not as Word instances. Pause instances have six attributes:\n",
    "\n",
    "* `entry` (the kind of Pause, e.g. `<SIL>`)\n",
    "* `beg` (pause onset time, in seconds)\n",
    "* `end` (pause offset time)\n",
    "* `dur` (duration)\n",
    "* `misaligned` (marked as True if the Pause has a negative duration)\n",
    "* `phones` (a list of references to Phone instances that are associated with this Pause, e.g. one or more `SIL` tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SIL> 0.102385 4.275744 4.173359 False\n"
     ]
    }
   ],
   "source": [
    "pause = track.words[1]\n",
    "\n",
    "print pause.entry, pause.beg, pause.end, pause.dur, pause.misaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Phone('SIL', 0.102385, 4.275744)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pause.phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phones\n",
    "\n",
    "The phones in a track can also be accessed directly through the `phones` attribute of a Track instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{B_TRANS} 0.0 0.102385 0.102385\n",
      "SIL 0.102385 4.275744 4.173359\n",
      "NOISE 4.275744 8.513763 4.238019\n",
      "IVER 8.513763 32.216575 23.702812\n",
      "k 32.216575 32.376593 0.160018\n",
      "ay 32.376593 32.622045 0.245452\n",
      "IVER 32.622045 37.129002 4.506957\n",
      "VOCNOISE 37.129002 38.123014 0.994012\n",
      "IVER 38.123014 44.617996 6.494982\n",
      "ah 44.617996 44.820731 0.202735\n"
     ]
    }
   ],
   "source": [
    "for phone in track.phones[:10]:\n",
    "    print phone.seg, phone.beg, phone.end, phone.dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log\n",
    "\n",
    "The list of entries in the Track's `.log` file can be accessed through the `log` attribute, which stores a list of the `LogEntry` instances for the Track. `LogEntry` instances have `entry`, `beg`, `end`, and `dur` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VOICE=modal> 0.0 61.142603 61.142603\n",
      "<VOICE=creaky> 61.142603 61.397647 0.255044\n",
      "<VOICE=modal> 61.397647 176.705681 115.308034\n",
      "<VOICE=creaky> 176.705681 177.442715 0.737034\n",
      "<VOICE=modal> 177.442715 208.458474 31.015759\n",
      "<VOICE=creaky> 208.458474 208.998197 0.539723\n",
      "<IVER_overlap-start> 208.998197 218.326046 9.327849\n",
      "<IVER_overlap-end> 218.326046 218.619639 0.293593\n",
      "<IVER_overlap-start> 218.619639 281.4126 62.792961\n",
      "<IVER_overlap-end> 281.4126 282.015381 0.602781\n",
      "<VOICE=modal> 282.015381 283.01414 0.998759\n",
      "<VOICE=creaky> 283.01414 283.342991 0.328851\n",
      "<IVER_overlap-start> 283.342991 286.3691 3.026109\n",
      "<IVER_overlap-end> 286.3691 286.587431 0.218331\n",
      "<IVER_overlap-start> 286.587431 358.243781 71.65635\n",
      "<IVER_overlap-end> 358.243781 358.766553 0.522772\n",
      "<VOICE=modal> 358.766553 570.891209 212.124656\n",
      "<VOICE=creaky> 570.891209 570.988848 0.097639\n",
      "<IVER_overlap-start> 570.988848 595.595736 24.606888\n",
      "<IVER_overlap-end> 595.595736 596.178854 0.583118\n"
     ]
    }
   ],
   "source": [
    "for log in track.log:\n",
    "    print log.entry, log.beg, log.end, log.dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `get_logs()` method of a Track to retrieve the log entries that overlap with the given timestamps.\n",
    "\n",
    "For example, the log entries that overlap with the interval from 60 seconds to 62 seconds can be found like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VOICE=modal> 0.0 61.142603\n",
      "<VOICE=creaky> 61.142603 61.397647\n",
      "<VOICE=modal> 61.397647 176.705681\n"
     ]
    }
   ],
   "source": [
    "logs = track.get_logs(60.0, 62.0)\n",
    "\n",
    "for log in logs:\n",
    "    print log.entry, log.beg, log.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `txt` attribute holds a list of speaker turns without timestamps, read from\n",
    "the `.txt` file in the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'okay <IVER>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track.txt[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavs\n",
    "\n",
    "If a Speaker instance is created with `load_wavs=True`, each Track will also have a `wav` attribute that stores a `Wave_read` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wave.Wave_read instance at 0x00000000068FE848>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker = buckeye.Speaker('./speakers/s01.zip', load_wavs=True)\n",
    "track = speaker[0]\n",
    "\n",
    "track.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can extract sound clips from the wav file with the `clip_wav()` method of each Track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track.clip_wav('myclip.wav', 60.0, 62.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a wav file in the current directory called `myclip.wav` which\n",
    "contains the sound between 60 and 62 seconds in the track audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `corpus()` generator function is a convenience for iterating through all of\n",
    "the speaker archives together. Put all forty speaker archives in one directory,\n",
    "such as `speakers/`. Create a new generator with this directory as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = buckeye.corpus('./speakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator will yield the `Speaker` instances in numerical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s01 s02 s03 s04 s05 s06 s07 s08 s09 s10 s11 s12 s13 s14 s15 s16 s17 s18 s19 s20 s21 s22 s23 s24 s25 s26 s27 s28 s29 s30 s31 s32 s33 s34 s35 s36 s37 s38 s39 s40\n"
     ]
    }
   ],
   "source": [
    "for speaker in corpus:\n",
    "    print speaker.name,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a `corpus()` generator, you can set `load_wavs` to `True` and it will be passed down to every `Track` instance, so that the all of the wav files will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = buckeye.corpus('./speakers', load_wavs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
